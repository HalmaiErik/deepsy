{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "097a9fd1-16ef-4036-8f44-191125b6bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from deepsy.core.model import Model\n",
    "from deepsy.core.nn import NeuralNetwork\n",
    "from deepsy.core.layer import Layer\n",
    "from deepsy.core.functions.activation_functions import *\n",
    "from deepsy.core.functions.loss_functions import *\n",
    "from deepsy.core.functions.optimizers import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70540557",
   "metadata": {},
   "source": [
    "# 1) titanic.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e420e6",
   "metadata": {},
   "source": [
    "### Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dddc9b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (891, 12)\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "[[-0.59214803  0.43255043 -0.47340772 -0.50216314 -0.56536789 -0.50986518\n",
      "   0.90208072 -0.73728105  0.73728105 -0.4817721  -0.3073897   0.61895873]\n",
      " [ 0.63843044  0.43255043 -0.47340772  0.78640362  1.76677466 -0.50986518\n",
      "  -1.10730408  1.35481262 -1.35481262  2.07334063 -0.3073897  -1.61380333]\n",
      " [-0.28450341 -0.47427882 -0.47340772 -0.48857985 -0.56536789 -0.50986518\n",
      "   0.90208072  1.35481262 -1.35481262 -0.4817721  -0.3073897   0.61895873]\n",
      " [ 0.40769698  0.43255043 -0.47340772  0.42049407  1.76677466 -0.50986518\n",
      "  -1.10730408  1.35481262 -1.35481262 -0.4817721  -0.3073897   0.61895873]\n",
      " [ 0.40769698 -0.47427882 -0.47340772 -0.48606443 -0.56536789 -0.50986518\n",
      "   0.90208072 -0.73728105  0.73728105 -0.4817721  -0.3073897   0.61895873]]\n",
      "\n",
      "[0 1 1 1 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/binary/titanic.csv')\n",
    "Y = dataset['Survived']\n",
    "X = dataset.drop(columns=['Survived'])\n",
    "X = X.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
    "X = pd.get_dummies(X, columns=['Pclass', 'Sex', 'Embarked'])\n",
    "\n",
    "X['Age'].fillna(X['Age'].mean(), inplace=True)\n",
    "X['Fare'].fillna(X['Fare'].mean(), inplace=True)\n",
    "\n",
    "X = (X - X.mean()) / X.std()\n",
    "\n",
    "X, Y = X.values, Y.values\n",
    "\n",
    "print('Dataset shape: {}'.format(dataset.shape))\n",
    "print(dataset.head())\n",
    "print()\n",
    "print(X[:5])\n",
    "print()\n",
    "print(Y[:5])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd3f61",
   "metadata": {},
   "source": [
    "### Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41faafa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: cost = 0.7315835607872729\n",
      "Epoch 2: cost = 0.7346364843634535\n",
      "Epoch 3: cost = 0.730866549247467\n",
      "Epoch 4: cost = 0.7128417610858127\n",
      "Epoch 5: cost = 0.7089894094210158\n",
      "Epoch 6: cost = 0.7196835476982486\n",
      "Epoch 7: cost = 0.7006294310031385\n",
      "Epoch 8: cost = 0.7070372362966171\n",
      "Epoch 9: cost = 0.7149159206187055\n",
      "Epoch 10: cost = 0.7036270669616692\n",
      "Epoch 11: cost = 0.7054023656833059\n",
      "Epoch 12: cost = 0.6948303118898463\n",
      "Epoch 13: cost = 0.7023103978400446\n",
      "Epoch 14: cost = 0.6964733051417826\n",
      "Epoch 15: cost = 0.6990097492409253\n",
      "Epoch 16: cost = 0.6892307370175489\n",
      "Epoch 17: cost = 0.6973147052282749\n",
      "Epoch 18: cost = 0.6909242384707911\n",
      "Epoch 19: cost = 0.6819836990109244\n",
      "Epoch 20: cost = 0.6931454638377845\n",
      "Epoch 21: cost = 0.6890183777368833\n",
      "Epoch 22: cost = 0.6814308800886664\n",
      "Epoch 23: cost = 0.6889575719927136\n",
      "Epoch 24: cost = 0.6886654114070844\n",
      "Epoch 25: cost = 0.6883035050515484\n",
      "Epoch 26: cost = 0.6889116308204744\n",
      "Epoch 27: cost = 0.6876766136217533\n",
      "Epoch 28: cost = 0.6871804632287266\n",
      "Epoch 29: cost = 0.6779319916347732\n",
      "Epoch 30: cost = 0.6780377297123034\n",
      "Epoch 31: cost = 0.6825938360730621\n",
      "Epoch 32: cost = 0.6863508563670837\n",
      "Epoch 33: cost = 0.6703167065247376\n",
      "Epoch 34: cost = 0.6818834926293944\n",
      "Epoch 35: cost = 0.6837330136215714\n",
      "Epoch 36: cost = 0.6862013611699217\n",
      "Epoch 37: cost = 0.676135854556904\n",
      "Epoch 38: cost = 0.67467264519067\n",
      "Epoch 39: cost = 0.6811737863576458\n",
      "Epoch 40: cost = 0.6683709119472755\n",
      "Epoch 41: cost = 0.6730441697899763\n",
      "Epoch 42: cost = 0.6637268384499393\n",
      "Epoch 43: cost = 0.6801477223498447\n",
      "Epoch 44: cost = 0.6738665771277833\n",
      "Epoch 45: cost = 0.6686529890065381\n",
      "Epoch 46: cost = 0.6707624771306194\n",
      "Epoch 47: cost = 0.6610229143887812\n",
      "Epoch 48: cost = 0.6672353883491854\n",
      "Epoch 49: cost = 0.6755960968584613\n",
      "Epoch 50: cost = 0.6672455050960057\n",
      "Epoch 51: cost = 0.6751093737783016\n",
      "Epoch 52: cost = 0.6667021917671582\n",
      "Epoch 53: cost = 0.6725156755151706\n",
      "Epoch 54: cost = 0.6639989581792184\n",
      "Epoch 55: cost = 0.6628615698540664\n",
      "Epoch 56: cost = 0.6604599818325628\n",
      "Epoch 57: cost = 0.6558567695897309\n",
      "Epoch 58: cost = 0.6669518108018538\n",
      "Epoch 59: cost = 0.6565373451663903\n",
      "Epoch 60: cost = 0.651879488935527\n",
      "Epoch 61: cost = 0.6578400403224559\n",
      "Epoch 62: cost = 0.6604956284560096\n",
      "Epoch 63: cost = 0.6625547096057548\n",
      "Epoch 64: cost = 0.6439459927338174\n",
      "Epoch 65: cost = 0.6634357466775082\n",
      "Epoch 66: cost = 0.6601716484280803\n",
      "Epoch 67: cost = 0.6502451547621227\n",
      "Epoch 68: cost = 0.6504856189473194\n",
      "Epoch 69: cost = 0.6545040062124671\n",
      "Epoch 70: cost = 0.6588431634337054\n",
      "Epoch 71: cost = 0.642074792249558\n",
      "Epoch 72: cost = 0.6475350718405731\n",
      "Epoch 73: cost = 0.6540901969160664\n",
      "Epoch 74: cost = 0.6433836846976423\n",
      "Epoch 75: cost = 0.6437213512881057\n",
      "Epoch 76: cost = 0.6430911460921607\n",
      "Epoch 77: cost = 0.6448302636132338\n",
      "Epoch 78: cost = 0.6420237544392672\n",
      "Epoch 79: cost = 0.6452023917704652\n",
      "Epoch 80: cost = 0.6415012061728333\n",
      "Epoch 81: cost = 0.6443988464559035\n",
      "Epoch 82: cost = 0.6432940041222587\n",
      "Epoch 83: cost = 0.6291655480122917\n",
      "Epoch 84: cost = 0.638216212291507\n",
      "Epoch 85: cost = 0.6436605672004855\n",
      "Epoch 86: cost = 0.6332637648395665\n",
      "Epoch 87: cost = 0.6293052275425305\n",
      "Epoch 88: cost = 0.6354948153480948\n",
      "Epoch 89: cost = 0.6382984511347473\n",
      "Epoch 90: cost = 0.6412407292550822\n",
      "Epoch 91: cost = 0.6447527458364266\n",
      "Epoch 92: cost = 0.6315513199212714\n",
      "Epoch 93: cost = 0.6268770522211369\n",
      "Epoch 94: cost = 0.628522372660975\n",
      "Epoch 95: cost = 0.6302328651282064\n",
      "Epoch 96: cost = 0.6365770864795404\n",
      "Epoch 97: cost = 0.6346638357163892\n",
      "Epoch 98: cost = 0.627462681883359\n",
      "Epoch 99: cost = 0.6215363951031674\n",
      "Epoch 100: cost = 0.6232641892567918\n",
      "Epoch 101: cost = 0.6273207244755002\n",
      "Epoch 102: cost = 0.6152406001321715\n",
      "Epoch 103: cost = 0.6202192611908784\n",
      "Epoch 104: cost = 0.6322874156810607\n",
      "Epoch 105: cost = 0.6369837227310996\n",
      "Epoch 106: cost = 0.6321200908639404\n",
      "Epoch 107: cost = 0.6304432437994743\n",
      "Epoch 108: cost = 0.6189989504650988\n",
      "Epoch 109: cost = 0.6099803863145804\n",
      "Epoch 110: cost = 0.6165286435150813\n",
      "Epoch 111: cost = 0.6181980409313699\n",
      "Epoch 112: cost = 0.6174426497830648\n",
      "Epoch 113: cost = 0.6260494431059382\n",
      "Epoch 114: cost = 0.6230045376724925\n",
      "Epoch 115: cost = 0.6189525530426171\n",
      "Epoch 116: cost = 0.6127780484390966\n",
      "Epoch 117: cost = 0.6158488333124537\n",
      "Epoch 118: cost = 0.6129966514468792\n",
      "Epoch 119: cost = 0.6223735741300059\n",
      "Epoch 120: cost = 0.6070157041698923\n",
      "Epoch 121: cost = 0.613577239705978\n",
      "Epoch 122: cost = 0.6023589472316181\n",
      "Epoch 123: cost = 0.6157951202309605\n",
      "Epoch 124: cost = 0.6046154816627012\n",
      "Epoch 125: cost = 0.6229144354311418\n",
      "Epoch 126: cost = 0.6124972247996177\n",
      "Epoch 127: cost = 0.6171244024272742\n",
      "Epoch 128: cost = 0.6173215449191344\n",
      "Epoch 129: cost = 0.6095224009218635\n",
      "Epoch 130: cost = 0.6052242311745992\n",
      "Epoch 131: cost = 0.6109446859204278\n",
      "Epoch 132: cost = 0.6032262631497965\n",
      "Epoch 133: cost = 0.6213998410833392\n",
      "Epoch 134: cost = 0.6116129776643726\n",
      "Epoch 135: cost = 0.6061040725404466\n",
      "Epoch 136: cost = 0.6013422962397853\n",
      "Epoch 137: cost = 0.6105892947496668\n",
      "Epoch 138: cost = 0.6017547134760525\n",
      "Epoch 139: cost = 0.5918732635122598\n",
      "Epoch 140: cost = 0.602778268163981\n",
      "Epoch 141: cost = 0.6051019868955684\n",
      "Epoch 142: cost = 0.6028438145017819\n",
      "Epoch 143: cost = 0.6049536475838043\n",
      "Epoch 144: cost = 0.5978549907616577\n",
      "Epoch 145: cost = 0.5903021745359875\n",
      "Epoch 146: cost = 0.6008513843940626\n",
      "Epoch 147: cost = 0.5927162948284591\n",
      "Epoch 148: cost = 0.598047896571304\n",
      "Epoch 149: cost = 0.5974688370226054\n",
      "Epoch 150: cost = 0.5914633447604076\n",
      "Epoch 151: cost = 0.5933808089325726\n",
      "Epoch 152: cost = 0.58979212590349\n",
      "Epoch 153: cost = 0.5950766469394966\n",
      "Epoch 154: cost = 0.5993781632854095\n",
      "Epoch 155: cost = 0.5839209950307405\n",
      "Epoch 156: cost = 0.5897597093114625\n",
      "Epoch 157: cost = 0.5792659818956704\n",
      "Epoch 158: cost = 0.571878927986566\n",
      "Epoch 159: cost = 0.5735575649465166\n",
      "Epoch 160: cost = 0.5931783410680711\n",
      "Epoch 161: cost = 0.5871232042621812\n",
      "Epoch 162: cost = 0.6010994479490275\n",
      "Epoch 163: cost = 0.5933452980861909\n",
      "Epoch 164: cost = 0.5900486325468265\n",
      "Epoch 165: cost = 0.574478515709927\n",
      "Epoch 166: cost = 0.5803797325125698\n",
      "Epoch 167: cost = 0.5833198544448458\n",
      "Epoch 168: cost = 0.5987797831188119\n",
      "Epoch 169: cost = 0.5797212299613839\n",
      "Epoch 170: cost = 0.5789045652505092\n",
      "Epoch 171: cost = 0.5697618946555373\n",
      "Epoch 172: cost = 0.601726865746448\n",
      "Epoch 173: cost = 0.6014591898968068\n",
      "Epoch 174: cost = 0.5828971303153226\n",
      "Epoch 175: cost = 0.5773787432040947\n",
      "Epoch 176: cost = 0.5970764250181543\n",
      "Epoch 177: cost = 0.5703908257210505\n",
      "Epoch 178: cost = 0.5835152686518565\n",
      "Epoch 179: cost = 0.5704028949104347\n",
      "Epoch 180: cost = 0.5706021933158293\n",
      "Epoch 181: cost = 0.5798095840801901\n",
      "Epoch 182: cost = 0.5784153790549089\n",
      "Epoch 183: cost = 0.5742082933022707\n",
      "Epoch 184: cost = 0.5788067280834623\n",
      "Epoch 185: cost = 0.5682803564708154\n",
      "Epoch 186: cost = 0.580714468452163\n",
      "Epoch 187: cost = 0.5744776559199134\n",
      "Epoch 188: cost = 0.5899166308201148\n",
      "Epoch 189: cost = 0.5732289810010305\n",
      "Epoch 190: cost = 0.5781153500202468\n",
      "Epoch 191: cost = 0.5732861786056584\n",
      "Epoch 192: cost = 0.5636488187522068\n",
      "Epoch 193: cost = 0.5725060450399757\n",
      "Epoch 194: cost = 0.569364444846732\n",
      "Epoch 195: cost = 0.586714406093831\n",
      "Epoch 196: cost = 0.5638655208596028\n",
      "Epoch 197: cost = 0.5791113017250688\n",
      "Epoch 198: cost = 0.5699642382785955\n",
      "Epoch 199: cost = 0.5782170641300686\n",
      "Epoch 200: cost = 0.576093753092868\n",
      "Epoch 201: cost = 0.5751760394894353\n",
      "Epoch 202: cost = 0.5705144154263238\n",
      "Epoch 203: cost = 0.580070362635078\n",
      "Epoch 204: cost = 0.5726920904955904\n",
      "Epoch 205: cost = 0.5668064738773108\n",
      "Epoch 206: cost = 0.5847156711338681\n",
      "Epoch 207: cost = 0.5706725281411323\n",
      "Epoch 208: cost = 0.5628849047779434\n",
      "Epoch 209: cost = 0.5775332000888951\n",
      "Epoch 210: cost = 0.575099796923564\n",
      "Epoch 211: cost = 0.5713979914242243\n",
      "Epoch 212: cost = 0.5716207154402463\n",
      "Epoch 213: cost = 0.5572699662880732\n",
      "Epoch 214: cost = 0.5620904453593031\n",
      "Epoch 215: cost = 0.5629538263081679\n",
      "Epoch 216: cost = 0.5793393076979835\n",
      "Epoch 217: cost = 0.5741906693587995\n",
      "Epoch 218: cost = 0.5610326672153246\n",
      "Epoch 219: cost = 0.5603738978975406\n",
      "Epoch 220: cost = 0.5651018658656789\n",
      "Epoch 221: cost = 0.563623031378223\n",
      "Epoch 222: cost = 0.580458901664927\n",
      "Epoch 223: cost = 0.5598614112515464\n",
      "Epoch 224: cost = 0.5592312471291352\n",
      "Epoch 225: cost = 0.5607907737410281\n",
      "Epoch 226: cost = 0.5710445021325106\n",
      "Epoch 227: cost = 0.5530509963101767\n",
      "Epoch 228: cost = 0.5786200513952938\n",
      "Epoch 229: cost = 0.5595632584226267\n",
      "Epoch 230: cost = 0.5510916990398963\n",
      "Epoch 231: cost = 0.5570791294888278\n",
      "Epoch 232: cost = 0.5779537292885747\n",
      "Epoch 233: cost = 0.5886933086659338\n",
      "Epoch 234: cost = 0.5591505827493224\n",
      "Epoch 235: cost = 0.5589604704664329\n",
      "Epoch 236: cost = 0.5642251152726817\n",
      "Epoch 237: cost = 0.5744374234926314\n",
      "Epoch 238: cost = 0.5371713746758159\n",
      "Epoch 239: cost = 0.5696683185699202\n",
      "Epoch 240: cost = 0.5641013287014148\n",
      "Epoch 241: cost = 0.5543616465676349\n",
      "Epoch 242: cost = 0.5639022976200169\n",
      "Epoch 243: cost = 0.5700545236998189\n",
      "Epoch 244: cost = 0.5605178044395275\n",
      "Epoch 245: cost = 0.5403202102431371\n",
      "Epoch 246: cost = 0.5671722982811221\n",
      "Epoch 247: cost = 0.5441103362160112\n",
      "Epoch 248: cost = 0.5577878352240092\n",
      "Epoch 249: cost = 0.5406465286144048\n",
      "Epoch 250: cost = 0.554681182593246\n",
      "Epoch 251: cost = 0.5655627252985698\n",
      "Epoch 252: cost = 0.5497879228517413\n",
      "Epoch 253: cost = 0.5613728083727951\n",
      "Epoch 254: cost = 0.553632472798691\n",
      "Epoch 255: cost = 0.5605259317465127\n",
      "Epoch 256: cost = 0.558236844982033\n",
      "Epoch 257: cost = 0.5706643143909487\n",
      "Epoch 258: cost = 0.5546118237529\n",
      "Epoch 259: cost = 0.5466748052983981\n",
      "Epoch 260: cost = 0.562185016141649\n",
      "Epoch 261: cost = 0.5571530120498255\n",
      "Epoch 262: cost = 0.5414329774516574\n",
      "Epoch 263: cost = 0.5444000272199161\n",
      "Epoch 264: cost = 0.5587730487089652\n",
      "Epoch 265: cost = 0.5628406989989488\n",
      "Epoch 266: cost = 0.5565788802612994\n",
      "Epoch 267: cost = 0.5545891414572159\n",
      "Epoch 268: cost = 0.5558328025668525\n",
      "Epoch 269: cost = 0.5610619121212572\n",
      "Epoch 270: cost = 0.562976057866362\n",
      "Epoch 271: cost = 0.5478952204298152\n",
      "Epoch 272: cost = 0.5498655129085529\n",
      "Epoch 273: cost = 0.5566125474654307\n",
      "Epoch 274: cost = 0.5485484342446854\n",
      "Epoch 275: cost = 0.5695777677722753\n",
      "Epoch 276: cost = 0.5472459504157215\n",
      "Epoch 277: cost = 0.5536298155616769\n",
      "Epoch 278: cost = 0.5602000243985148\n",
      "Epoch 279: cost = 0.5495713434132117\n",
      "Epoch 280: cost = 0.5481934784533153\n",
      "Epoch 281: cost = 0.551843874540529\n",
      "Epoch 282: cost = 0.5410058398573938\n",
      "Epoch 283: cost = 0.5590236716020771\n",
      "Epoch 284: cost = 0.5426564715793261\n",
      "Epoch 285: cost = 0.5523582746059746\n",
      "Epoch 286: cost = 0.5444924358128511\n",
      "Epoch 287: cost = 0.5297966515797939\n",
      "Epoch 288: cost = 0.5448977607426244\n",
      "Epoch 289: cost = 0.5510543642771164\n",
      "Epoch 290: cost = 0.5360003819272269\n",
      "Epoch 291: cost = 0.558400115480715\n",
      "Epoch 292: cost = 0.5446479592152422\n",
      "Epoch 293: cost = 0.5622609231463951\n",
      "Epoch 294: cost = 0.5449709738487947\n",
      "Epoch 295: cost = 0.5353482456052697\n",
      "Epoch 296: cost = 0.559295408750658\n",
      "Epoch 297: cost = 0.5152643244855969\n",
      "Epoch 298: cost = 0.5528571602096565\n",
      "Epoch 299: cost = 0.5426046731292976\n",
      "Epoch 300: cost = 0.5548202463308807\n",
      "Epoch 301: cost = 0.5341581315299865\n",
      "Epoch 302: cost = 0.5496736601499632\n",
      "Epoch 303: cost = 0.5245768376786938\n",
      "Epoch 304: cost = 0.5429288726476912\n",
      "Epoch 305: cost = 0.5574337616733263\n",
      "Epoch 306: cost = 0.5514567404831036\n",
      "Epoch 307: cost = 0.5457658310846975\n",
      "Epoch 308: cost = 0.5452123221917908\n",
      "Epoch 309: cost = 0.5386878710759545\n",
      "Epoch 310: cost = 0.5377716112937152\n",
      "Epoch 311: cost = 0.5304544295219208\n",
      "Epoch 312: cost = 0.5390449507294084\n",
      "Epoch 313: cost = 0.5477560840334814\n",
      "Epoch 314: cost = 0.5267016076436803\n",
      "Epoch 315: cost = 0.5475970459955171\n",
      "Epoch 316: cost = 0.5337432173869145\n",
      "Epoch 317: cost = 0.5307993558439228\n",
      "Epoch 318: cost = 0.5408279591116999\n",
      "Epoch 319: cost = 0.527538310265139\n",
      "Epoch 320: cost = 0.5303604666136553\n",
      "Epoch 321: cost = 0.5427437518114125\n",
      "Epoch 322: cost = 0.5481843943438284\n",
      "Epoch 323: cost = 0.5198103138220997\n",
      "Epoch 324: cost = 0.549871382614604\n",
      "Epoch 325: cost = 0.5388707012860561\n",
      "Epoch 326: cost = 0.5363603715993492\n",
      "Epoch 327: cost = 0.5530678465564619\n",
      "Epoch 328: cost = 0.5315448887538167\n",
      "Epoch 329: cost = 0.5287628477316338\n",
      "Epoch 330: cost = 0.5324562170776475\n",
      "Epoch 331: cost = 0.5376712619390622\n",
      "Epoch 332: cost = 0.5358265213001175\n",
      "Epoch 333: cost = 0.531345252220371\n",
      "Epoch 334: cost = 0.5423597210852603\n",
      "Epoch 335: cost = 0.5225354866473668\n",
      "Epoch 336: cost = 0.5261797368415773\n",
      "Epoch 337: cost = 0.5384138203444412\n",
      "Epoch 338: cost = 0.5406587496047083\n",
      "Epoch 339: cost = 0.5368259791252477\n",
      "Epoch 340: cost = 0.5404498481601356\n",
      "Epoch 341: cost = 0.5306994510259959\n",
      "Epoch 342: cost = 0.5153817448491823\n",
      "Epoch 343: cost = 0.5478526776082636\n",
      "Epoch 344: cost = 0.5478652454166781\n",
      "Epoch 345: cost = 0.5353296148967315\n",
      "Epoch 346: cost = 0.538032269383809\n",
      "Epoch 347: cost = 0.5381511999388146\n",
      "Epoch 348: cost = 0.5198068055085562\n",
      "Epoch 349: cost = 0.5415135899410491\n",
      "Epoch 350: cost = 0.5246334830467743\n",
      "Epoch 351: cost = 0.5356185066658286\n",
      "Epoch 352: cost = 0.5310627892330557\n",
      "Epoch 353: cost = 0.530248796632311\n",
      "Epoch 354: cost = 0.5352900784254793\n",
      "Epoch 355: cost = 0.5262311622059617\n",
      "Epoch 356: cost = 0.5316494455613743\n",
      "Epoch 357: cost = 0.5338437346972675\n",
      "Epoch 358: cost = 0.546005258018008\n",
      "Epoch 359: cost = 0.5245261849466332\n",
      "Epoch 360: cost = 0.5434659398984832\n",
      "Epoch 361: cost = 0.5367421747771483\n",
      "Epoch 362: cost = 0.5309756173678216\n",
      "Epoch 363: cost = 0.522224069613222\n",
      "Epoch 364: cost = 0.5158159784090162\n",
      "Epoch 365: cost = 0.5055519898291669\n",
      "Epoch 366: cost = 0.52450234973682\n",
      "Epoch 367: cost = 0.5289436377827864\n",
      "Epoch 368: cost = 0.5197509213525398\n",
      "Epoch 369: cost = 0.5239864342743601\n",
      "Epoch 370: cost = 0.5343233629721544\n",
      "Epoch 371: cost = 0.5233155360686762\n",
      "Epoch 372: cost = 0.5430108305011677\n",
      "Epoch 373: cost = 0.538268457953523\n",
      "Epoch 374: cost = 0.5242289206212503\n",
      "Epoch 375: cost = 0.5417155940766198\n",
      "Epoch 376: cost = 0.5245032445707123\n",
      "Epoch 377: cost = 0.5256811883841176\n",
      "Epoch 378: cost = 0.513830728036799\n",
      "Epoch 379: cost = 0.5276370641924956\n",
      "Epoch 380: cost = 0.512045187187615\n",
      "Epoch 381: cost = 0.5411187385160375\n",
      "Epoch 382: cost = 0.527718820484155\n",
      "Epoch 383: cost = 0.5277234250155588\n",
      "Epoch 384: cost = 0.5291585809946026\n",
      "Epoch 385: cost = 0.507974914270861\n",
      "Epoch 386: cost = 0.5250402526776837\n",
      "Epoch 387: cost = 0.5140708755188146\n",
      "Epoch 388: cost = 0.5198932447272315\n",
      "Epoch 389: cost = 0.5274381739070987\n",
      "Epoch 390: cost = 0.5337586780381512\n",
      "Epoch 391: cost = 0.5275486603665763\n",
      "Epoch 392: cost = 0.5258781890105784\n",
      "Epoch 393: cost = 0.5271939763035681\n",
      "Epoch 394: cost = 0.5239973718497541\n",
      "Epoch 395: cost = 0.5247801910171425\n",
      "Epoch 396: cost = 0.5193386750118634\n",
      "Epoch 397: cost = 0.5305182366553082\n",
      "Epoch 398: cost = 0.5163979950168971\n",
      "Epoch 399: cost = 0.5188308989151384\n",
      "Epoch 400: cost = 0.519242158798105\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "nn = NeuralNetwork(layers=[\n",
    "    Layer(nr_neurons=12, nr_in_features=12, activation_func=ReLU()),\n",
    "    Layer(nr_neurons=16, nr_in_features=12, activation_func=ReLU(), dropout_rate=0.15),\n",
    "    Layer(nr_neurons=8, nr_in_features=16, activation_func=ReLU(), dropout_rate=0.15),\n",
    "    Layer(nr_neurons=1, nr_in_features=8, activation_func=Sigmoid())\n",
    "])\n",
    "\n",
    "model = Model(nn, loss_func=BinaryCrossEntropy(), optimizer=GradientDescent(learning_rate=0.2))\n",
    "model.train(X_train.T, Y_train.T, nr_epochs=400, reg_lambda=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11211a6a",
   "metadata": {},
   "source": [
    "### Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "970d01ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7932960893854749\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n"
     ]
    }
   ],
   "source": [
    "Y_predicted = model.predict(X_test.T)\n",
    "acc = sum((Y_predicted.reshape(Y_test.shape) > 0.5) == Y_test) / len(Y_test)\n",
    "print('Accuracy: {}'.format(acc))\n",
    "for i in range(len(Y_predicted[0])):\n",
    "    print('predicted: {}   actual: {}'.format((Y_predicted[0][i] > 0.5).astype(int), Y_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5dcff1",
   "metadata": {},
   "source": [
    "### Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebbdef30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W': array([[-0.54498117,  0.02941081, -0.93485692, -0.34346945,  0.60608652,\n",
      "         0.73841659,  0.11937626, -0.10676991,  0.39640713,  0.16729861,\n",
      "        -0.50152983, -0.26863477],\n",
      "       [ 0.38008134, -0.02012299,  0.11502053,  0.4021095 , -0.02705442,\n",
      "        -0.3129756 ,  0.24432841,  0.05794498,  0.96060367,  0.45931097,\n",
      "        -0.69118143,  1.26381282],\n",
      "       [ 0.14043181, -0.02847278, -0.96390143,  0.25428025, -0.69154621,\n",
      "         0.95668832, -0.03771398,  0.46663264,  0.11441669, -0.24377148,\n",
      "        -0.59610401,  0.71752043],\n",
      "       [-0.1772373 , -0.4020625 ,  0.07229826,  0.69099429,  0.83636497,\n",
      "         0.10629988, -0.61137939,  0.05411629,  0.07613289, -0.43242972,\n",
      "        -0.14694231, -0.43741037],\n",
      "       [ 0.12978711, -0.10765753, -0.91692404,  0.05195995, -0.2983985 ,\n",
      "         0.0514821 ,  0.80273987,  0.44065525, -0.18074015,  0.09725239,\n",
      "        -0.52971259,  0.20977122],\n",
      "       [-0.02062587,  0.08579149, -0.40060272, -0.19797855, -0.33617036,\n",
      "         0.12404502,  0.24959088, -0.51986839, -0.18216518,  0.52495606,\n",
      "        -0.11401264, -0.40706093],\n",
      "       [ 0.03977159,  0.15813657,  0.23185637, -1.01862906, -0.03363   ,\n",
      "        -0.45830238, -0.36116264,  0.32861671,  0.72574256, -0.46445436,\n",
      "         0.2330019 ,  0.13845082],\n",
      "       [-0.11341373, -0.02548938, -0.41729045,  0.2258547 , -0.57512473,\n",
      "        -0.21540097,  0.70507061,  0.1643854 , -0.54294061, -0.21334451,\n",
      "         0.01719934,  0.1195408 ],\n",
      "       [-0.6998537 ,  0.5326415 , -0.31874792, -0.085372  ,  0.40805882,\n",
      "         0.38654135, -1.0055223 , -0.62605821,  0.44107303, -0.05183798,\n",
      "        -0.2598517 ,  0.10209819],\n",
      "       [-0.16216947, -0.40204824,  0.07519783,  0.2406704 , -0.34884445,\n",
      "        -0.71782245, -0.23152767, -0.6592863 ,  0.78844794,  0.30143613,\n",
      "        -0.64160655, -0.19380926],\n",
      "       [-0.13690839,  0.4904154 , -0.04292693,  0.33838465,  0.17182399,\n",
      "         0.03463955, -0.65602253, -0.06514316,  0.62229217, -0.46075713,\n",
      "         0.34644513, -0.08017023],\n",
      "       [-0.32451392,  0.56234788, -0.70437829, -0.16123151, -0.69028646,\n",
      "         0.4434351 , -0.58579189, -0.59896257,  0.50292974, -0.18211043,\n",
      "        -0.34880181, -0.2687567 ]]), 'b': array([[ 0.01365986],\n",
      "       [ 0.09554296],\n",
      "       [-0.01696798],\n",
      "       [ 0.10122656],\n",
      "       [-0.01251243],\n",
      "       [ 0.05067193],\n",
      "       [ 0.04387723],\n",
      "       [-0.08496941],\n",
      "       [-0.03627273],\n",
      "       [ 0.09391677],\n",
      "       [ 0.00955673],\n",
      "       [-0.04226017]])}\n",
      "{'W': array([[-0.06783845, -0.41642113, -0.54258481,  0.30017687, -0.54893646,\n",
      "        -0.19186154, -0.00788918, -0.54992041,  0.18503962, -0.30617141,\n",
      "        -0.03670388, -0.22036171],\n",
      "       [ 0.34408184,  0.41772909,  0.22602693, -0.70052783,  0.24850329,\n",
      "        -0.09150572, -0.30782258, -0.23313997,  0.04855125,  1.06563117,\n",
      "        -0.09026424,  0.39790936],\n",
      "       [ 1.29000463, -0.03331504,  1.0615457 , -0.42918687, -0.096576  ,\n",
      "        -0.51287589, -0.05958091, -0.17726114,  0.57897545, -0.1364502 ,\n",
      "        -0.25508404, -0.50967856],\n",
      "       [-0.2127593 ,  0.33793179, -0.3107857 , -0.54607621, -0.32614938,\n",
      "        -0.34028967, -0.24718418,  0.61058555, -0.66180142, -0.17946343,\n",
      "        -0.16227995, -0.36438343],\n",
      "       [ 0.01387953,  0.51078352, -0.99991611,  0.14016804, -0.44181689,\n",
      "         0.37189862, -0.50870987, -0.1071606 , -0.25583163, -0.46610516,\n",
      "         0.79484833, -0.3233645 ],\n",
      "       [ 0.1474742 ,  0.3211234 ,  0.14163069, -0.31560722, -0.33849704,\n",
      "         0.26727521,  0.06826465,  1.5784404 , -0.47168067, -0.31840173,\n",
      "        -0.15464772, -0.05785402],\n",
      "       [-0.27195619, -0.21442314,  0.86083866,  0.29347503, -0.17787472,\n",
      "        -0.2862002 , -0.15127466, -0.30690849, -0.20513543, -0.35682429,\n",
      "         0.17159505, -0.98321562],\n",
      "       [ 0.31022891, -0.59476807, -0.47422842,  0.52948945, -0.13565649,\n",
      "         0.09120322, -0.00385245, -0.8331032 , -0.13067399,  0.09706415,\n",
      "         0.33830077, -0.10862066],\n",
      "       [ 0.26902208,  0.39981295,  0.32606369, -0.1888977 , -0.92294548,\n",
      "         0.29981719,  0.80148593, -0.50494915, -0.02961169,  0.30819243,\n",
      "         0.75237194,  0.30777223],\n",
      "       [ 0.4430391 , -0.34552466, -0.07726627,  0.54006281, -0.34577984,\n",
      "        -0.25619038, -0.00344864, -0.72028643, -0.51864344, -0.34223094,\n",
      "         0.4646062 ,  0.153142  ],\n",
      "       [ 0.10320662,  0.18461816,  0.07187734,  0.31622   , -0.60015411,\n",
      "         0.14409569, -0.63281573,  0.19872823, -0.74347798, -0.04930075,\n",
      "         0.16769241,  0.03620242],\n",
      "       [-0.54483417, -0.04521569,  0.27586995, -0.17784864,  0.30260704,\n",
      "        -0.42077778,  0.27792817, -0.11820028, -0.19723389, -0.95918229,\n",
      "        -0.6698325 , -0.99340497],\n",
      "       [ 0.45765152, -0.58498916,  0.61203098,  0.05355864, -0.20053668,\n",
      "         0.06790791, -0.02823956, -0.65249692,  0.19316206, -0.35309442,\n",
      "         0.32169454,  0.74026741],\n",
      "       [ 0.60914115,  0.83082719, -0.13751382,  0.58739046, -0.59443688,\n",
      "        -0.01585182, -0.28318883,  0.0844203 ,  0.22234114, -0.14923988,\n",
      "         0.05582214,  0.00548536],\n",
      "       [-0.05341026, -0.52064211,  0.04335082,  0.21947998, -0.52613196,\n",
      "         0.3312744 , -0.36875977,  0.23727757, -0.22944172, -0.10336893,\n",
      "         0.2389195 , -0.57750076],\n",
      "       [ 0.37387375,  0.07859219, -0.06503106, -0.03304828,  0.17587129,\n",
      "        -0.10737786,  0.76337631, -0.28293806, -0.74105958,  0.7973259 ,\n",
      "        -0.29860325, -0.25769057]]), 'b': array([[-0.00587568],\n",
      "       [ 0.03997444],\n",
      "       [ 0.00051066],\n",
      "       [-0.00057993],\n",
      "       [ 0.00949194],\n",
      "       [-0.01854405],\n",
      "       [ 0.10431025],\n",
      "       [ 0.00483055],\n",
      "       [-0.05507799],\n",
      "       [ 0.07971537],\n",
      "       [ 0.09454026],\n",
      "       [ 0.00010852],\n",
      "       [-0.02589722],\n",
      "       [ 0.01200891],\n",
      "       [-0.06518763],\n",
      "       [ 0.0532846 ]])}\n",
      "{'W': array([[ 0.45866228, -0.00249682, -0.31635209,  0.36557547,  0.52498426,\n",
      "         0.03356007,  0.16577469,  0.34951034, -0.05811138, -0.37202482,\n",
      "        -0.03825589,  0.25143141, -0.07786935, -0.52380251, -0.17192947,\n",
      "        -0.15185211],\n",
      "       [ 0.35327499, -0.20442547, -0.19465352, -0.53659817,  0.11466545,\n",
      "         0.30564016,  0.33557541,  0.1261839 , -0.63976738,  0.65591541,\n",
      "         0.71405948, -0.09334806,  0.04346455, -0.0167824 , -0.33478368,\n",
      "        -0.03167469],\n",
      "       [ 0.24578343,  0.27302705, -0.20016009, -0.05759406,  0.29102199,\n",
      "         1.09863019, -0.18119301,  0.32780167,  0.02013818,  0.04644583,\n",
      "        -0.18145797,  0.22891721, -0.09752178, -0.04483363, -0.20828247,\n",
      "         0.31146962],\n",
      "       [ 0.54142924, -0.54601366, -0.32817538, -0.70175496,  0.25252533,\n",
      "         0.20192521, -0.16999019, -0.08686384,  0.48337291, -0.44736676,\n",
      "        -0.10971082,  0.40611449,  0.2140375 , -0.2751436 , -0.37102246,\n",
      "        -0.14166102],\n",
      "       [-0.2607647 , -0.60726328,  0.20862359, -0.23185026,  0.01972542,\n",
      "        -0.36854601,  0.27032699,  0.20516039, -0.39007715, -0.11013009,\n",
      "        -0.36355302, -0.17477727, -0.2672595 ,  0.03190385,  0.27763038,\n",
      "        -0.71904077],\n",
      "       [-0.07946859, -0.03220888,  0.22590388,  0.33480871, -0.03633915,\n",
      "        -0.72788933,  0.37883725, -0.23978303, -0.09885574, -0.36183622,\n",
      "        -0.18512998, -0.19906979, -0.26776557, -0.35985034, -0.01645039,\n",
      "        -0.23480061],\n",
      "       [ 0.19907634,  0.35379739, -0.0284038 ,  0.25399471,  0.07182423,\n",
      "        -0.10251575, -0.48977632, -0.86557331,  0.17208665,  0.15757868,\n",
      "         0.30093712, -0.22517098,  0.04431069,  0.18656162, -0.31320056,\n",
      "         0.44144438],\n",
      "       [-0.13154325, -0.08285499,  0.45454016,  0.69606484, -0.05538794,\n",
      "         0.3337527 , -0.06744989,  0.33964174,  0.1104281 , -0.06347011,\n",
      "         0.17162702,  0.27354449, -0.01715352, -0.39499093,  0.29822593,\n",
      "        -0.61324397]]), 'b': array([[-0.00310001],\n",
      "       [ 0.04137802],\n",
      "       [-0.00086482],\n",
      "       [ 0.04190982],\n",
      "       [ 0.00445153],\n",
      "       [ 0.01604044],\n",
      "       [ 0.13431969],\n",
      "       [ 0.01074969]])}\n",
      "{'W': array([[ 0.13921875,  0.93262431, -0.20876212, -0.5333323 ,  0.04678169,\n",
      "         0.13598837, -0.56142713,  0.20231343]]), 'b': array([[-0.09025691]])}\n"
     ]
    }
   ],
   "source": [
    "for layer in model.get_neural_network().get_layers():\n",
    "    print(layer.get_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872b862e",
   "metadata": {},
   "source": [
    "# 2) Employee.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4301ca",
   "metadata": {},
   "source": [
    "### Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13a9c6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (4653, 9)\n",
      "   Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched  \\\n",
      "0  Bachelors         2017  Bangalore            3   34    Male          No   \n",
      "1  Bachelors         2013       Pune            1   28  Female          No   \n",
      "2  Bachelors         2014  New Delhi            3   38  Female          No   \n",
      "3    Masters         2016  Bangalore            3   27    Male          No   \n",
      "4    Masters         2017       Pune            3   24    Male         Yes   \n",
      "\n",
      "   ExperienceInCurrentDomain  LeaveOrNot  \n",
      "0                          0           0  \n",
      "1                          3           1  \n",
      "2                          2           0  \n",
      "3                          5           1  \n",
      "4                          2           1  \n",
      "\n",
      "[[ 1.03952665  0.53744523  0.95454254 -1.86470098  0.54044268 -0.48052341\n",
      "  -0.20000086  1.04316163 -0.57522042 -0.61197491 -0.82146269  0.82146269\n",
      "   0.33832885 -0.33832885]\n",
      " [-1.10711376 -3.024852   -0.28870069  0.06054761  0.54044268 -0.48052341\n",
      "  -0.20000086 -0.95841819 -0.57522042  1.63370274  1.21707912 -1.21707912\n",
      "   0.33832885 -0.33832885]\n",
      " [-0.57045366  0.53744523  1.78337136 -0.58120192  0.54044268 -0.48052341\n",
      "  -0.20000086 -0.95841819  1.73809039 -0.61197491  1.21707912 -1.21707912\n",
      "   0.33832885 -0.33832885]\n",
      " [ 0.50286655  0.53744523 -0.49590789  1.34404667 -1.84993734  2.08061682\n",
      "  -0.20000086  1.04316163 -0.57522042 -0.61197491 -0.82146269  0.82146269\n",
      "   0.33832885 -0.33832885]\n",
      " [ 1.03952665  0.53744523 -1.11752951 -0.58120192 -1.84993734  2.08061682\n",
      "  -0.20000086 -0.95841819 -0.57522042  1.63370274 -0.82146269  0.82146269\n",
      "  -2.95506895  2.95506895]]\n",
      "\n",
      "[0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/binary/Employee.csv')\n",
    "Y = dataset['LeaveOrNot']\n",
    "X = dataset.drop(columns=['LeaveOrNot'])\n",
    "X = pd.get_dummies(X, columns=['Education', 'City', 'Gender', 'EverBenched'])\n",
    "\n",
    "X = (X - X.mean()) / X.std()\n",
    "\n",
    "X, Y = X.values, Y.values\n",
    "\n",
    "print('Dataset shape: {}'.format(dataset.shape))\n",
    "print(dataset.head())\n",
    "print()\n",
    "print(X[:5])\n",
    "print()\n",
    "print(Y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68599a05",
   "metadata": {},
   "source": [
    "### Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86b6f2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: cost = 0.9662521704853717\n",
      "Epoch 2: cost = 0.9002246094400375\n",
      "Epoch 3: cost = 0.8387590938696978\n",
      "Epoch 4: cost = 0.8016330983534719\n",
      "Epoch 5: cost = 0.7650810823968069\n",
      "Epoch 6: cost = 0.7439934945048581\n",
      "Epoch 7: cost = 0.7188157328424173\n",
      "Epoch 8: cost = 0.7099660663228402\n",
      "Epoch 9: cost = 0.6944740926679744\n",
      "Epoch 10: cost = 0.6829052689029167\n",
      "Epoch 11: cost = 0.6743591328499103\n",
      "Epoch 12: cost = 0.6676899297305788\n",
      "Epoch 13: cost = 0.6665966269701958\n",
      "Epoch 14: cost = 0.6628385555654904\n",
      "Epoch 15: cost = 0.655886414889925\n",
      "Epoch 16: cost = 0.6563547252033289\n",
      "Epoch 17: cost = 0.6492915720847161\n",
      "Epoch 18: cost = 0.6468859394915096\n",
      "Epoch 19: cost = 0.6464360663841505\n",
      "Epoch 20: cost = 0.6456907751851779\n",
      "Epoch 21: cost = 0.6402460513877384\n",
      "Epoch 22: cost = 0.6362363466275228\n",
      "Epoch 23: cost = 0.6380442152962964\n",
      "Epoch 24: cost = 0.6420816878245487\n",
      "Epoch 25: cost = 0.6319847951901558\n",
      "Epoch 26: cost = 0.6342126088062405\n",
      "Epoch 27: cost = 0.6310047203310775\n",
      "Epoch 28: cost = 0.6324901037530631\n",
      "Epoch 29: cost = 0.6316502755139043\n",
      "Epoch 30: cost = 0.6299357306613194\n",
      "Epoch 31: cost = 0.628391674875799\n",
      "Epoch 32: cost = 0.6300980142661744\n",
      "Epoch 33: cost = 0.6291378730887669\n",
      "Epoch 34: cost = 0.629207192952751\n",
      "Epoch 35: cost = 0.6265237390430242\n",
      "Epoch 36: cost = 0.6255041145924751\n",
      "Epoch 37: cost = 0.6276579316474696\n",
      "Epoch 38: cost = 0.6179011453205646\n",
      "Epoch 39: cost = 0.6252050659062444\n",
      "Epoch 40: cost = 0.6227993266149112\n",
      "Epoch 41: cost = 0.6208385445654246\n",
      "Epoch 42: cost = 0.6223067864222905\n",
      "Epoch 43: cost = 0.6211068596392219\n",
      "Epoch 44: cost = 0.6199560349974979\n",
      "Epoch 45: cost = 0.6207938415650889\n",
      "Epoch 46: cost = 0.6245660062725014\n",
      "Epoch 47: cost = 0.6133557221493159\n",
      "Epoch 48: cost = 0.6171318696194864\n",
      "Epoch 49: cost = 0.6148702604757288\n",
      "Epoch 50: cost = 0.6145650862864982\n",
      "Epoch 51: cost = 0.6182507062886281\n",
      "Epoch 52: cost = 0.6115965984363462\n",
      "Epoch 53: cost = 0.6146432551425375\n",
      "Epoch 54: cost = 0.6160132581562829\n",
      "Epoch 55: cost = 0.6094947219129622\n",
      "Epoch 56: cost = 0.615955885053854\n",
      "Epoch 57: cost = 0.6153012355721496\n",
      "Epoch 58: cost = 0.6099830900683948\n",
      "Epoch 59: cost = 0.6100755541315792\n",
      "Epoch 60: cost = 0.6110977129693226\n",
      "Epoch 61: cost = 0.6128375674683186\n",
      "Epoch 62: cost = 0.6109281442160436\n",
      "Epoch 63: cost = 0.6095028772736261\n",
      "Epoch 64: cost = 0.6122987495690072\n",
      "Epoch 65: cost = 0.6044564079426971\n",
      "Epoch 66: cost = 0.6070858246832831\n",
      "Epoch 67: cost = 0.6127902591173416\n",
      "Epoch 68: cost = 0.606121382153566\n",
      "Epoch 69: cost = 0.6095118241479677\n",
      "Epoch 70: cost = 0.6070385132139321\n",
      "Epoch 71: cost = 0.6036850100366653\n",
      "Epoch 72: cost = 0.5996897207412685\n",
      "Epoch 73: cost = 0.6064391647382056\n",
      "Epoch 74: cost = 0.60731581953756\n",
      "Epoch 75: cost = 0.6071049386353853\n",
      "Epoch 76: cost = 0.6030344125826339\n",
      "Epoch 77: cost = 0.5995869523361331\n",
      "Epoch 78: cost = 0.5999917652539082\n",
      "Epoch 79: cost = 0.5951806786816078\n",
      "Epoch 80: cost = 0.6087353724012279\n",
      "Epoch 81: cost = 0.6017212867241533\n",
      "Epoch 82: cost = 0.594239890037776\n",
      "Epoch 83: cost = 0.599329140100807\n",
      "Epoch 84: cost = 0.6044481890197548\n",
      "Epoch 85: cost = 0.593996202732405\n",
      "Epoch 86: cost = 0.6026693897060531\n",
      "Epoch 87: cost = 0.5963956911372633\n",
      "Epoch 88: cost = 0.5993013332828191\n",
      "Epoch 89: cost = 0.5971438038920843\n",
      "Epoch 90: cost = 0.5967757189950703\n",
      "Epoch 91: cost = 0.5914958177960407\n",
      "Epoch 92: cost = 0.5958672759154148\n",
      "Epoch 93: cost = 0.5909665546701434\n",
      "Epoch 94: cost = 0.5873349991626107\n",
      "Epoch 95: cost = 0.5992395841037196\n",
      "Epoch 96: cost = 0.5906338558256062\n",
      "Epoch 97: cost = 0.5932412293418377\n",
      "Epoch 98: cost = 0.5967819853055156\n",
      "Epoch 99: cost = 0.5943674471962054\n",
      "Epoch 100: cost = 0.5910477212096247\n",
      "Epoch 101: cost = 0.5964171115176111\n",
      "Epoch 102: cost = 0.5919534849143085\n",
      "Epoch 103: cost = 0.5899514051542647\n",
      "Epoch 104: cost = 0.591437906603106\n",
      "Epoch 105: cost = 0.5934113360666031\n",
      "Epoch 106: cost = 0.5889587324621126\n",
      "Epoch 107: cost = 0.5856819120957225\n",
      "Epoch 108: cost = 0.597571343243494\n",
      "Epoch 109: cost = 0.592337600406496\n",
      "Epoch 110: cost = 0.5892163410918504\n",
      "Epoch 111: cost = 0.5909095924642301\n",
      "Epoch 112: cost = 0.5956754834838008\n",
      "Epoch 113: cost = 0.5934476877095906\n",
      "Epoch 114: cost = 0.5879804667281452\n",
      "Epoch 115: cost = 0.5896485351266408\n",
      "Epoch 116: cost = 0.5856763217213632\n",
      "Epoch 117: cost = 0.585853707498722\n",
      "Epoch 118: cost = 0.5838897548481181\n",
      "Epoch 119: cost = 0.588973181590884\n",
      "Epoch 120: cost = 0.5882838551829189\n",
      "Epoch 121: cost = 0.5814213611592949\n",
      "Epoch 122: cost = 0.5900495683157643\n",
      "Epoch 123: cost = 0.5895483863560269\n",
      "Epoch 124: cost = 0.587435152352154\n",
      "Epoch 125: cost = 0.5849228714840833\n",
      "Epoch 126: cost = 0.5812656123179171\n",
      "Epoch 127: cost = 0.5870409960318937\n",
      "Epoch 128: cost = 0.5873471041600853\n",
      "Epoch 129: cost = 0.5880217061436759\n",
      "Epoch 130: cost = 0.5866497492512558\n",
      "Epoch 131: cost = 0.5804223448954723\n",
      "Epoch 132: cost = 0.5796571219637877\n",
      "Epoch 133: cost = 0.5866974032867486\n",
      "Epoch 134: cost = 0.5835382579080797\n",
      "Epoch 135: cost = 0.5825377129401915\n",
      "Epoch 136: cost = 0.5821647810285978\n",
      "Epoch 137: cost = 0.5845686861556789\n",
      "Epoch 138: cost = 0.5811841098022152\n",
      "Epoch 139: cost = 0.5790307158795434\n",
      "Epoch 140: cost = 0.5813206505519157\n",
      "Epoch 141: cost = 0.584905972331225\n",
      "Epoch 142: cost = 0.580102502171815\n",
      "Epoch 143: cost = 0.5806916956225995\n",
      "Epoch 144: cost = 0.5787489176036232\n",
      "Epoch 145: cost = 0.5795504661691881\n",
      "Epoch 146: cost = 0.580620524553675\n",
      "Epoch 147: cost = 0.5841316392795044\n",
      "Epoch 148: cost = 0.5774526456794281\n",
      "Epoch 149: cost = 0.576211583335107\n",
      "Epoch 150: cost = 0.5767509475515483\n",
      "Epoch 151: cost = 0.579201625778919\n",
      "Epoch 152: cost = 0.5718502950000665\n",
      "Epoch 153: cost = 0.5723662023454487\n",
      "Epoch 154: cost = 0.575747374599397\n",
      "Epoch 155: cost = 0.578346715425148\n",
      "Epoch 156: cost = 0.5756043035254608\n",
      "Epoch 157: cost = 0.5786644993029775\n",
      "Epoch 158: cost = 0.5738273734060586\n",
      "Epoch 159: cost = 0.5773577129979248\n",
      "Epoch 160: cost = 0.563407411879339\n",
      "Epoch 161: cost = 0.5748985002228899\n",
      "Epoch 162: cost = 0.5784675364652895\n",
      "Epoch 163: cost = 0.5715653177676487\n",
      "Epoch 164: cost = 0.5770243803069594\n",
      "Epoch 165: cost = 0.5723546942196688\n",
      "Epoch 166: cost = 0.5772867428739771\n",
      "Epoch 167: cost = 0.5770432618168733\n",
      "Epoch 168: cost = 0.5716141638188407\n",
      "Epoch 169: cost = 0.5690460410671168\n",
      "Epoch 170: cost = 0.5715616882248649\n",
      "Epoch 171: cost = 0.5766010498207452\n",
      "Epoch 172: cost = 0.5719878253095994\n",
      "Epoch 173: cost = 0.5730918651671117\n",
      "Epoch 174: cost = 0.5683416097100138\n",
      "Epoch 175: cost = 0.5676801693175867\n",
      "Epoch 176: cost = 0.579118883960686\n",
      "Epoch 177: cost = 0.5703480622791905\n",
      "Epoch 178: cost = 0.5667294250022664\n",
      "Epoch 179: cost = 0.5652504795068551\n",
      "Epoch 180: cost = 0.5748269640065251\n",
      "Epoch 181: cost = 0.5656616051107249\n",
      "Epoch 182: cost = 0.5634899137140225\n",
      "Epoch 183: cost = 0.5599372696144531\n",
      "Epoch 184: cost = 0.5682421433260304\n",
      "Epoch 185: cost = 0.5742402400875968\n",
      "Epoch 186: cost = 0.5709594459896432\n",
      "Epoch 187: cost = 0.5714411468331432\n",
      "Epoch 188: cost = 0.5628736600289461\n",
      "Epoch 189: cost = 0.5666067085876223\n",
      "Epoch 190: cost = 0.5681903532409774\n",
      "Epoch 191: cost = 0.5600683160008402\n",
      "Epoch 192: cost = 0.5694341711896461\n",
      "Epoch 193: cost = 0.5661768750092318\n",
      "Epoch 194: cost = 0.5593113189358047\n",
      "Epoch 195: cost = 0.5647666190225876\n",
      "Epoch 196: cost = 0.5614427545596333\n",
      "Epoch 197: cost = 0.5641002351261484\n",
      "Epoch 198: cost = 0.5621953915050841\n",
      "Epoch 199: cost = 0.5638852428583163\n",
      "Epoch 200: cost = 0.5658133357444003\n",
      "Epoch 201: cost = 0.5743621542998871\n",
      "Epoch 202: cost = 0.566251096844747\n",
      "Epoch 203: cost = 0.560758931936267\n",
      "Epoch 204: cost = 0.5579360332317822\n",
      "Epoch 205: cost = 0.5685279771013027\n",
      "Epoch 206: cost = 0.5666314249941456\n",
      "Epoch 207: cost = 0.5673556677261985\n",
      "Epoch 208: cost = 0.5605183647466584\n",
      "Epoch 209: cost = 0.5604869123925715\n",
      "Epoch 210: cost = 0.5626955328038242\n",
      "Epoch 211: cost = 0.5625890758827388\n",
      "Epoch 212: cost = 0.5629493358621688\n",
      "Epoch 213: cost = 0.5653428717649557\n",
      "Epoch 214: cost = 0.5608767491006196\n",
      "Epoch 215: cost = 0.5617242598543748\n",
      "Epoch 216: cost = 0.5626611492634346\n",
      "Epoch 217: cost = 0.563794351547506\n",
      "Epoch 218: cost = 0.5588703086874998\n",
      "Epoch 219: cost = 0.5606564391934183\n",
      "Epoch 220: cost = 0.5627110041634036\n",
      "Epoch 221: cost = 0.5627237927677714\n",
      "Epoch 222: cost = 0.5593128850981732\n",
      "Epoch 223: cost = 0.5568674972392444\n",
      "Epoch 224: cost = 0.5611431158206439\n",
      "Epoch 225: cost = 0.5596852932928531\n",
      "Epoch 226: cost = 0.5618434717285195\n",
      "Epoch 227: cost = 0.5590402485119194\n",
      "Epoch 228: cost = 0.5627190323963528\n",
      "Epoch 229: cost = 0.5577670908639478\n",
      "Epoch 230: cost = 0.5554340158825501\n",
      "Epoch 231: cost = 0.5588286258646078\n",
      "Epoch 232: cost = 0.5573583943735789\n",
      "Epoch 233: cost = 0.5588578097631819\n",
      "Epoch 234: cost = 0.5546229151633968\n",
      "Epoch 235: cost = 0.555671038698171\n",
      "Epoch 236: cost = 0.552288835388085\n",
      "Epoch 237: cost = 0.5586830358700444\n",
      "Epoch 238: cost = 0.5632720331120914\n",
      "Epoch 239: cost = 0.5518673193282257\n",
      "Epoch 240: cost = 0.5565047944975264\n",
      "Epoch 241: cost = 0.5626694530356364\n",
      "Epoch 242: cost = 0.55996466267193\n",
      "Epoch 243: cost = 0.5624701899692539\n",
      "Epoch 244: cost = 0.5517707292358642\n",
      "Epoch 245: cost = 0.5526698288211321\n",
      "Epoch 246: cost = 0.5513630928369653\n",
      "Epoch 247: cost = 0.556811541686727\n",
      "Epoch 248: cost = 0.552313439402669\n",
      "Epoch 249: cost = 0.5567825726059338\n",
      "Epoch 250: cost = 0.558385435410608\n",
      "Epoch 251: cost = 0.5550598120292182\n",
      "Epoch 252: cost = 0.5478584648803765\n",
      "Epoch 253: cost = 0.5527155228768722\n",
      "Epoch 254: cost = 0.5540005192942768\n",
      "Epoch 255: cost = 0.5519440691486547\n",
      "Epoch 256: cost = 0.5539971359169383\n",
      "Epoch 257: cost = 0.54849924198731\n",
      "Epoch 258: cost = 0.5510877069942611\n",
      "Epoch 259: cost = 0.5521303438894598\n",
      "Epoch 260: cost = 0.5467570255941715\n",
      "Epoch 261: cost = 0.5623080167923679\n",
      "Epoch 262: cost = 0.5535053742804134\n",
      "Epoch 263: cost = 0.5583825207824904\n",
      "Epoch 264: cost = 0.550013415195137\n",
      "Epoch 265: cost = 0.5547104296149016\n",
      "Epoch 266: cost = 0.5543060609253831\n",
      "Epoch 267: cost = 0.5473808775713804\n",
      "Epoch 268: cost = 0.5542492409079816\n",
      "Epoch 269: cost = 0.5454566323759886\n",
      "Epoch 270: cost = 0.5540751569768042\n",
      "Epoch 271: cost = 0.5463827846302657\n",
      "Epoch 272: cost = 0.549179183920692\n",
      "Epoch 273: cost = 0.546681801619149\n",
      "Epoch 274: cost = 0.5488771623892293\n",
      "Epoch 275: cost = 0.560235427711541\n",
      "Epoch 276: cost = 0.5437019104817449\n",
      "Epoch 277: cost = 0.5580085133227937\n",
      "Epoch 278: cost = 0.5485556181530379\n",
      "Epoch 279: cost = 0.5482415877189115\n",
      "Epoch 280: cost = 0.5412620514914104\n",
      "Epoch 281: cost = 0.552315520376819\n",
      "Epoch 282: cost = 0.5421595633744606\n",
      "Epoch 283: cost = 0.5503163628105839\n",
      "Epoch 284: cost = 0.5474654294523325\n",
      "Epoch 285: cost = 0.549844419279622\n",
      "Epoch 286: cost = 0.5443371603675587\n",
      "Epoch 287: cost = 0.5437811663921932\n",
      "Epoch 288: cost = 0.5454149604087829\n",
      "Epoch 289: cost = 0.5487878938409358\n",
      "Epoch 290: cost = 0.5402341964674449\n",
      "Epoch 291: cost = 0.5439168424604948\n",
      "Epoch 292: cost = 0.5499315910467388\n",
      "Epoch 293: cost = 0.5506511722201397\n",
      "Epoch 294: cost = 0.5466033540705189\n",
      "Epoch 295: cost = 0.5480363472971317\n",
      "Epoch 296: cost = 0.5438617543470625\n",
      "Epoch 297: cost = 0.5492597844653584\n",
      "Epoch 298: cost = 0.537665870942388\n",
      "Epoch 299: cost = 0.5460934272404288\n",
      "Epoch 300: cost = 0.5482316845711407\n",
      "Epoch 301: cost = 0.542593330121452\n",
      "Epoch 302: cost = 0.5468495188134292\n",
      "Epoch 303: cost = 0.5430458419102934\n",
      "Epoch 304: cost = 0.5457959446108183\n",
      "Epoch 305: cost = 0.5390455354281091\n",
      "Epoch 306: cost = 0.5418548232518368\n",
      "Epoch 307: cost = 0.5413583131445797\n",
      "Epoch 308: cost = 0.5470131770310828\n",
      "Epoch 309: cost = 0.5430947165764622\n",
      "Epoch 310: cost = 0.5497061178777715\n",
      "Epoch 311: cost = 0.5448764325275303\n",
      "Epoch 312: cost = 0.5488771583780943\n",
      "Epoch 313: cost = 0.5417642252305911\n",
      "Epoch 314: cost = 0.5417373743305076\n",
      "Epoch 315: cost = 0.5462916623781986\n",
      "Epoch 316: cost = 0.5469709197626449\n",
      "Epoch 317: cost = 0.5477088090401426\n",
      "Epoch 318: cost = 0.5442327256196574\n",
      "Epoch 319: cost = 0.5420295168286053\n",
      "Epoch 320: cost = 0.5432298617463888\n",
      "Epoch 321: cost = 0.5403526190714986\n",
      "Epoch 322: cost = 0.5362949958528682\n",
      "Epoch 323: cost = 0.5357342296338982\n",
      "Epoch 324: cost = 0.5459149621631785\n",
      "Epoch 325: cost = 0.5388479230991168\n",
      "Epoch 326: cost = 0.5424052073550266\n",
      "Epoch 327: cost = 0.5473221498267531\n",
      "Epoch 328: cost = 0.5383141314583216\n",
      "Epoch 329: cost = 0.5454641327151459\n",
      "Epoch 330: cost = 0.5435917065112227\n",
      "Epoch 331: cost = 0.5471698155319928\n",
      "Epoch 332: cost = 0.5415206966058654\n",
      "Epoch 333: cost = 0.5402525487810373\n",
      "Epoch 334: cost = 0.5483541336699536\n",
      "Epoch 335: cost = 0.5370400278268922\n",
      "Epoch 336: cost = 0.5455749185021703\n",
      "Epoch 337: cost = 0.5407270190513023\n",
      "Epoch 338: cost = 0.5412730150889911\n",
      "Epoch 339: cost = 0.5413103953135513\n",
      "Epoch 340: cost = 0.5415971156864408\n",
      "Epoch 341: cost = 0.5327436175668274\n",
      "Epoch 342: cost = 0.5388392708587023\n",
      "Epoch 343: cost = 0.5423268568538542\n",
      "Epoch 344: cost = 0.5328217384653429\n",
      "Epoch 345: cost = 0.5342398996188763\n",
      "Epoch 346: cost = 0.5412785096006889\n",
      "Epoch 347: cost = 0.5342918109645268\n",
      "Epoch 348: cost = 0.5435671605775165\n",
      "Epoch 349: cost = 0.5322331635762901\n",
      "Epoch 350: cost = 0.5409505620026622\n",
      "Epoch 351: cost = 0.5416179731034517\n",
      "Epoch 352: cost = 0.5387182797758328\n",
      "Epoch 353: cost = 0.542094188797945\n",
      "Epoch 354: cost = 0.5417600030036697\n",
      "Epoch 355: cost = 0.5423787699395829\n",
      "Epoch 356: cost = 0.532016401415901\n",
      "Epoch 357: cost = 0.536015158168078\n",
      "Epoch 358: cost = 0.5349584896812976\n",
      "Epoch 359: cost = 0.5437692288678533\n",
      "Epoch 360: cost = 0.5425600378119179\n",
      "Epoch 361: cost = 0.5350887182156406\n",
      "Epoch 362: cost = 0.5338415998171183\n",
      "Epoch 363: cost = 0.5399703391503037\n",
      "Epoch 364: cost = 0.5450123563227165\n",
      "Epoch 365: cost = 0.5331871571634798\n",
      "Epoch 366: cost = 0.533033858555355\n",
      "Epoch 367: cost = 0.5362822066561775\n",
      "Epoch 368: cost = 0.5409162549802368\n",
      "Epoch 369: cost = 0.5321970911845035\n",
      "Epoch 370: cost = 0.5378520541761161\n",
      "Epoch 371: cost = 0.5369393760302267\n",
      "Epoch 372: cost = 0.5244518781659331\n",
      "Epoch 373: cost = 0.5379810056393952\n",
      "Epoch 374: cost = 0.5311122311959944\n",
      "Epoch 375: cost = 0.539288809461344\n",
      "Epoch 376: cost = 0.5349911101673319\n",
      "Epoch 377: cost = 0.5337069651514227\n",
      "Epoch 378: cost = 0.5278935878917961\n",
      "Epoch 379: cost = 0.5367792949678587\n",
      "Epoch 380: cost = 0.53160174565351\n",
      "Epoch 381: cost = 0.5363770391150445\n",
      "Epoch 382: cost = 0.5292781567482817\n",
      "Epoch 383: cost = 0.5374332739833071\n",
      "Epoch 384: cost = 0.5342237634140211\n",
      "Epoch 385: cost = 0.5365133861109523\n",
      "Epoch 386: cost = 0.5336834243153802\n",
      "Epoch 387: cost = 0.5425210014926245\n",
      "Epoch 388: cost = 0.5328508024190537\n",
      "Epoch 389: cost = 0.5307836922850098\n",
      "Epoch 390: cost = 0.5296193968406571\n",
      "Epoch 391: cost = 0.5329443888098754\n",
      "Epoch 392: cost = 0.5322356374933217\n",
      "Epoch 393: cost = 0.5337932898648733\n",
      "Epoch 394: cost = 0.5313989379917881\n",
      "Epoch 395: cost = 0.5348271019101883\n",
      "Epoch 396: cost = 0.5393837420904404\n",
      "Epoch 397: cost = 0.5338441875871074\n",
      "Epoch 398: cost = 0.5366674021566035\n",
      "Epoch 399: cost = 0.5302777956912956\n",
      "Epoch 400: cost = 0.5350993592244222\n",
      "Epoch 401: cost = 0.539276107245917\n",
      "Epoch 402: cost = 0.5388871249238176\n",
      "Epoch 403: cost = 0.5359776309591372\n",
      "Epoch 404: cost = 0.5285353386015958\n",
      "Epoch 405: cost = 0.5306588269351914\n",
      "Epoch 406: cost = 0.5424534886388153\n",
      "Epoch 407: cost = 0.5424630029302139\n",
      "Epoch 408: cost = 0.5278932556483603\n",
      "Epoch 409: cost = 0.5310210694764455\n",
      "Epoch 410: cost = 0.5320393881132773\n",
      "Epoch 411: cost = 0.5262578092854184\n",
      "Epoch 412: cost = 0.5272076232371292\n",
      "Epoch 413: cost = 0.5308085916416577\n",
      "Epoch 414: cost = 0.5265659593303379\n",
      "Epoch 415: cost = 0.5341613822840093\n",
      "Epoch 416: cost = 0.5314327131979952\n",
      "Epoch 417: cost = 0.5270603525010986\n",
      "Epoch 418: cost = 0.5312719514800216\n",
      "Epoch 419: cost = 0.5354972579064919\n",
      "Epoch 420: cost = 0.5306682648267289\n",
      "Epoch 421: cost = 0.5314522320487233\n",
      "Epoch 422: cost = 0.5387273507129814\n",
      "Epoch 423: cost = 0.5298379897423684\n",
      "Epoch 424: cost = 0.522236277988335\n",
      "Epoch 425: cost = 0.5243244794432946\n",
      "Epoch 426: cost = 0.5226383620135483\n",
      "Epoch 427: cost = 0.5265662148748412\n",
      "Epoch 428: cost = 0.5296640238526217\n",
      "Epoch 429: cost = 0.5194334529996754\n",
      "Epoch 430: cost = 0.5246154301257819\n",
      "Epoch 431: cost = 0.5288559431957136\n",
      "Epoch 432: cost = 0.5262280400512556\n",
      "Epoch 433: cost = 0.5283963070238413\n",
      "Epoch 434: cost = 0.5162722707067595\n",
      "Epoch 435: cost = 0.5255631102993746\n",
      "Epoch 436: cost = 0.5321443634343099\n",
      "Epoch 437: cost = 0.5237108090765239\n",
      "Epoch 438: cost = 0.5251199330270933\n",
      "Epoch 439: cost = 0.5256358461382984\n",
      "Epoch 440: cost = 0.5214211689863464\n",
      "Epoch 441: cost = 0.5243646826969419\n",
      "Epoch 442: cost = 0.5268607727593504\n",
      "Epoch 443: cost = 0.5262975303272402\n",
      "Epoch 444: cost = 0.5307093978772219\n",
      "Epoch 445: cost = 0.5316004990630817\n",
      "Epoch 446: cost = 0.5148286419433494\n",
      "Epoch 447: cost = 0.5257505426154089\n",
      "Epoch 448: cost = 0.5247733959237738\n",
      "Epoch 449: cost = 0.5301982102291479\n",
      "Epoch 450: cost = 0.5327014525141311\n",
      "Epoch 451: cost = 0.5204454831403029\n",
      "Epoch 452: cost = 0.5251732132601836\n",
      "Epoch 453: cost = 0.5202464551746212\n",
      "Epoch 454: cost = 0.536288024353746\n",
      "Epoch 455: cost = 0.5254604401470007\n",
      "Epoch 456: cost = 0.5206408692623635\n",
      "Epoch 457: cost = 0.5289801793454647\n",
      "Epoch 458: cost = 0.5267942463599314\n",
      "Epoch 459: cost = 0.5203579264434808\n",
      "Epoch 460: cost = 0.5227334400951767\n",
      "Epoch 461: cost = 0.5248408526135183\n",
      "Epoch 462: cost = 0.5303297832472426\n",
      "Epoch 463: cost = 0.5253130208491046\n",
      "Epoch 464: cost = 0.5221500315759076\n",
      "Epoch 465: cost = 0.5295438893171268\n",
      "Epoch 466: cost = 0.5260924858139759\n",
      "Epoch 467: cost = 0.5285803640625557\n",
      "Epoch 468: cost = 0.5273999603620634\n",
      "Epoch 469: cost = 0.5196395589264514\n",
      "Epoch 470: cost = 0.5151618493271792\n",
      "Epoch 471: cost = 0.520529007004297\n",
      "Epoch 472: cost = 0.5214439825917079\n",
      "Epoch 473: cost = 0.5242619583909773\n",
      "Epoch 474: cost = 0.5197278226244125\n",
      "Epoch 475: cost = 0.5331139788043908\n",
      "Epoch 476: cost = 0.5174921691703701\n",
      "Epoch 477: cost = 0.5250177189635343\n",
      "Epoch 478: cost = 0.5209396073998284\n",
      "Epoch 479: cost = 0.5243114966494832\n",
      "Epoch 480: cost = 0.5216407608913107\n",
      "Epoch 481: cost = 0.5309601819716817\n",
      "Epoch 482: cost = 0.530176053492435\n",
      "Epoch 483: cost = 0.5247084151068315\n",
      "Epoch 484: cost = 0.5171215732401864\n",
      "Epoch 485: cost = 0.517857025238138\n",
      "Epoch 486: cost = 0.5226513888837423\n",
      "Epoch 487: cost = 0.5226529266253912\n",
      "Epoch 488: cost = 0.517340603296873\n",
      "Epoch 489: cost = 0.5236541998100035\n",
      "Epoch 490: cost = 0.521056886262167\n",
      "Epoch 491: cost = 0.5133181804763657\n",
      "Epoch 492: cost = 0.5187847911765031\n",
      "Epoch 493: cost = 0.5153654812138684\n",
      "Epoch 494: cost = 0.5280104845102845\n",
      "Epoch 495: cost = 0.5216754998578934\n",
      "Epoch 496: cost = 0.5201752660314996\n",
      "Epoch 497: cost = 0.5198521462792917\n",
      "Epoch 498: cost = 0.5208284391922902\n",
      "Epoch 499: cost = 0.5178822021177489\n",
      "Epoch 500: cost = 0.5299295403486756\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "nn = NeuralNetwork(layers=[\n",
    "    Layer(nr_neurons=12, nr_in_features=14, activation_func=ReLU()),\n",
    "    Layer(nr_neurons=16, nr_in_features=12, activation_func=ReLU(), dropout_rate=0.3),\n",
    "    Layer(nr_neurons=8, nr_in_features=16, activation_func=ReLU(), dropout_rate=0.3),\n",
    "    Layer(nr_neurons=1, nr_in_features=8, activation_func=Sigmoid())\n",
    "])\n",
    "\n",
    "model = Model(nn, loss_func=BinaryCrossEntropy(), optimizer=GradientDescent(0.4))\n",
    "model.train(X_train.T, Y_train.T, nr_epochs=500, reg_lambda=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677c7524",
   "metadata": {},
   "source": [
    "### Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b42660a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7980665950590763\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 0   actual: 0\n",
      "predicted: 1   actual: 1\n",
      "predicted: 0   actual: 1\n"
     ]
    }
   ],
   "source": [
    "Y_predicted = model.predict(X_test.T)\n",
    "acc = sum((Y_predicted.reshape(Y_test.shape) > 0.5) == Y_test) / len(Y_test)\n",
    "print('Accuracy: {}'.format(acc))\n",
    "for i in range(len(Y_predicted[0])):\n",
    "    print('predicted: {}   actual: {}'.format((Y_predicted[0][i] > 0.5).astype(int), Y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "662bb4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86       603\n",
      "           1       0.82      0.54      0.65       328\n",
      "\n",
      "    accuracy                           0.80       931\n",
      "   macro avg       0.81      0.74      0.76       931\n",
      "weighted avg       0.80      0.80      0.79       931\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test, (Y_predicted.reshape(Y_test.shape) > 0.5).astype(int)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
